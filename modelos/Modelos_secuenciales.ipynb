{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelos.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx82H4OmEZVR",
        "colab_type": "text"
      },
      "source": [
        "#Modelos de redes secuenciales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JASz-63lY64O",
        "colab_type": "text"
      },
      "source": [
        "##Activación para Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCkvfteNY-od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LMG: Variable para controlar si estamos en Colab o no y aplicar a las celdas:\n",
        "inColab = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU6hOISSQ1fn",
        "colab_type": "text"
      },
      "source": [
        "En la siguiente celda, montamos la carpeta personal del Drive en Colab en caso de estar en este entorno. Pedirá un código al que se accede desde el enlace que facilita."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrIqkj0YPNeB",
        "colab_type": "code",
        "outputId": "6cae06e0-470e-462d-f3e7-3254f2759563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#LMG: Para Google CoLab tener el repo de Drive:\n",
        "if inColab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPdkUOGTfXeo",
        "colab_type": "text"
      },
      "source": [
        "##Carga de librerías y preparación de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZo4Cp7RezA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, LSTM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jElUruaqeoFw",
        "colab_type": "code",
        "outputId": "1d92c028-c3fd-4313-bc12-04a1c4e8ef99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "#LMG: Para CoLab en sample_data:\n",
        "if inColab:\n",
        "  data_consumo = pd.read_csv(\"/content/drive/My Drive/TFM/data/data_total.csv\")\n",
        "else:\n",
        "  data_consumo = pd.read_csv(\"data_total.csv\")\n",
        "\n",
        "x_data = data_consumo.drop(['PVPC_DEF','PVPC_2_PED_NOC','PVPC_ELEC_NOC'], axis=1).copy()\n",
        "# Delete unconsistent columns\n",
        "x_data = x_data.drop(columns=['fecha','fecha_dia'])\n",
        "\n",
        "#y_data = data_consumo[['PVPC_DEF','PVPC_2_PED_NOC','PVPC_ELEC_NOC']]\n",
        "y_data = data_consumo[['PVPC_DEF']]\n",
        "\n",
        "x_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Demanda</th>\n",
              "      <th>Eolica</th>\n",
              "      <th>Nuclear</th>\n",
              "      <th>Solar</th>\n",
              "      <th>Solar_Fotovoltaica</th>\n",
              "      <th>Solar_Termica</th>\n",
              "      <th>Termica_Renovable</th>\n",
              "      <th>Prevista</th>\n",
              "      <th>Programada</th>\n",
              "      <th>Holiday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>24984.666667</td>\n",
              "      <td>1003.666667</td>\n",
              "      <td>6012.833333</td>\n",
              "      <td>402.166667</td>\n",
              "      <td>33.0</td>\n",
              "      <td>368.500000</td>\n",
              "      <td>580.166667</td>\n",
              "      <td>24691.833333</td>\n",
              "      <td>24517.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>23550.833333</td>\n",
              "      <td>899.000000</td>\n",
              "      <td>6013.166667</td>\n",
              "      <td>174.833333</td>\n",
              "      <td>33.0</td>\n",
              "      <td>141.333333</td>\n",
              "      <td>584.166667</td>\n",
              "      <td>23440.000000</td>\n",
              "      <td>23169.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>22648.166667</td>\n",
              "      <td>927.500000</td>\n",
              "      <td>6013.500000</td>\n",
              "      <td>103.833333</td>\n",
              "      <td>33.0</td>\n",
              "      <td>70.666667</td>\n",
              "      <td>585.833333</td>\n",
              "      <td>22521.166667</td>\n",
              "      <td>22437.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>22203.833333</td>\n",
              "      <td>935.666667</td>\n",
              "      <td>6013.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>33.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>588.500000</td>\n",
              "      <td>22335.333333</td>\n",
              "      <td>22281.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>21987.833333</td>\n",
              "      <td>900.833333</td>\n",
              "      <td>6014.166667</td>\n",
              "      <td>101.666667</td>\n",
              "      <td>33.0</td>\n",
              "      <td>68.166667</td>\n",
              "      <td>589.000000</td>\n",
              "      <td>22177.833333</td>\n",
              "      <td>21910.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0       Demanda       Eolica  ...      Prevista  Programada  Holiday\n",
              "0           0  24984.666667  1003.666667  ...  24691.833333     24517.0      0.0\n",
              "1           1  23550.833333   899.000000  ...  23440.000000     23169.0      0.0\n",
              "2           2  22648.166667   927.500000  ...  22521.166667     22437.0      0.0\n",
              "3           3  22203.833333   935.666667  ...  22335.333333     22281.0      0.0\n",
              "4           4  21987.833333   900.833333  ...  22177.833333     21910.0      0.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtIkBQUL74un",
        "colab_type": "code",
        "outputId": "3671333e-8658-4c61-b459-9374f55d7ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Split the data\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data, test_size=0.33, shuffle=True)\n",
        "\n",
        "#Reshape for the LSTM\n",
        "x_train = x_train.to_numpy()\n",
        "x_valid = x_valid.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_valid = y_valid.to_numpy()\n",
        "\n",
        "print('Xtrain_dim:', x_train.shape)\n",
        "print('Ytrain_dim:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain_dim: (22510, 11)\n",
            "Ytrain_dim: (22510, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24K8XGk7Eirr",
        "colab_type": "text"
      },
      "source": [
        "##Ejemplo de LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AOyGsv9Qx20",
        "colab_type": "text"
      },
      "source": [
        "Basado en el ejemplo completo que está explicado en https://adventuresinmachinelearning.com/keras-lstm-tutorial/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H95jxroYS-i7",
        "colab_type": "text"
      },
      "source": [
        "Definamos los tamaños de nuestra red y algunas variables adicionales:\n",
        "\n",
        "En nuestro caso, la entrada va a ser de *1* **x** *nº de datos tomados* **x** *nº de variables independientes*, siendo:\n",
        "\n",
        "- batch_size, para cada instante tomamos los datos en paquetes.\n",
        "- nº de datos tomados o num_steps, esto es, en el análisis secuencial cada registro energético completo con el que contamos, o en términos más coloquiales, cuántas filas del dataset se tienen en cuenta .\n",
        "- nº de variables independientes o num_var, cada registro en los datos de entrada, o en términos más coloquiales, cada columna del dataset.\n",
        "\n",
        "Además:\n",
        "\n",
        "- hidden_size, número de unidades en cada célula del LSTM.\n",
        "\n",
        "- A la salida, tenemos los tres valores a estimar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdkHAnbBS-_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "num_steps = 25\n",
        "num_var = x_train.shape[1]\n",
        "hidden_size = 500\n",
        "output_size = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BeK_KtV1bW-",
        "colab_type": "text"
      },
      "source": [
        "Para que se ejecute en paquetes, replicamos el dataset de n en n lotes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVU0VJ48QxXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X = list()\n",
        "  for i in range(len(sequence)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the sequence\n",
        "    if end_ix > len(sequence)-1:\n",
        "      break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x = sequence[i:end_ix,:]\n",
        "    X.append(seq_x)\n",
        "\n",
        "  return np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rk6a3pF2w7t",
        "colab_type": "text"
      },
      "source": [
        "Después, estandarizamos los datos y aplicamos la función a la x e y, agrupando las salidas por paquetes de num_steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6c_j69eRfQv",
        "colab_type": "code",
        "outputId": "42f7b8d0-ac93-4bde-be6e-6aaad08dc364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scaler = StandardScaler()\n",
        "x_train_est = scaler.fit_transform(x_train)\n",
        "y_train_est = scaler.fit_transform(y_train)\n",
        "x_valid_est = scaler.fit_transform(x_valid)\n",
        "y_valid_est = scaler.fit_transform(y_valid)\n",
        "\n",
        "x_train_data = split_sequence(x_train_est, num_steps)\n",
        "y_train_data = y_train_est[num_steps:,:]\n",
        "x_valid_data = split_sequence(x_valid_est, num_steps)\n",
        "y_valid_data = y_valid_est[num_steps:,:]\n",
        "\n",
        "print('Entrenamiento:',x_train_data.shape, y_train_data.shape)\n",
        "print('Test:',x_valid_data.shape, y_valid_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrenamiento: (22485, 25, 11) (22485, 1)\n",
            "Test: (11063, 25, 11) (11063, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xArQLrgE8g-",
        "colab_type": "text"
      },
      "source": [
        "A la capa LSTM se le pasa cada vez un instante, siendo el primero el t1, el segundo el t2, etc.\n",
        "\n",
        "Respecto al ejemplo en la página, hemos:\n",
        "- Quitado el embedding inicial, ya que no necesitamos codificar la entrada (ya son valores en sí mismos).\n",
        "- Cambiado el hidden-layer-size. En la página dicen que se suele poner al tamaño de entrada de cada registro. Viene a ser el símil de unidades en una capa densa.\n",
        "- Dejado una única capa LSTM.\n",
        "- Eliminado el dropout.\n",
        "- TimeDistributed usa una capa densa para cada step del entrenamiento. La quitamos también y dejamos la densa exclusivamente, ya que hace la salida muy grande.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1xmNZVPHVVd",
        "colab_type": "code",
        "outputId": "7bacd442-fa78-40e8-a326-e17783702743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='relu', return_sequences=True, input_shape=(num_steps,num_var),kernel_initializer='zeros'))\n",
        "model.add(LSTM(hidden_size, activation='relu'))\n",
        "model.add(Dense(output_size, activation='linear'))\n",
        "\n",
        "# compile mode\n",
        "opt = SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='mse',metrics=['mse'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_38 (LSTM)               (None, 25, 500)           1024000   \n",
            "_________________________________________________________________\n",
            "lstm_39 (LSTM)               (None, 500)               2002000   \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 501       \n",
            "=================================================================\n",
            "Total params: 3,026,501\n",
            "Trainable params: 3,026,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCUaeBOpRgbN",
        "colab_type": "text"
      },
      "source": [
        "Y entrenamos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFKaJjCCHlT1",
        "colab_type": "code",
        "outputId": "8d6a4fc9-70cb-4f6e-92d2-22776679e6b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "history_train = model.fit(x_train_data, y_train_data, epochs=10, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history_train.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  160/22485 [..............................] - ETA: 29:15 - loss: 1.1366 - mean_squared_error: 1.1366"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg6-Qtdai-3y",
        "colab_type": "text"
      },
      "source": [
        "Para el test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAlosve8i-nO",
        "colab_type": "code",
        "outputId": "ad3ed65f-3a2e-44f1-e03c-cb3986746f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scores_test = model.evaluate(x_valid_data, y_valid_data, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# summarize loss\n",
        "print(\"%s: %.2f\" % (model.metrics_names[1], scores_test[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11063/11063 [==============================] - 2s 185us/step\n",
            "mean_squared_error: 99.98%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}