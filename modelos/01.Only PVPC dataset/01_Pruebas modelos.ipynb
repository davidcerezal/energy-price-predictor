{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_Pruebas modelos.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cx82H4OmEZVR","colab_type":"text"},"source":["#Pruebas modelos (Only PVPC)"]},{"cell_type":"markdown","metadata":{"id":"JASz-63lY64O","colab_type":"text"},"source":["##Activación para Colab"]},{"cell_type":"code","metadata":{"id":"uCkvfteNY-od","colab_type":"code","colab":{}},"source":["#LMG: Variable para controlar si estamos en Colab o no y aplicar a las celdas:\n","inColab = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CU6hOISSQ1fn","colab_type":"text"},"source":["En la siguiente celda, montamos la carpeta personal del Drive en Colab en caso de estar en este entorno. Pedirá un código al que se accede desde el enlace que facilita."]},{"cell_type":"code","metadata":{"id":"RrIqkj0YPNeB","colab_type":"code","outputId":"b06bc05b-2f10-475d-8518-e57eb8cd20e3","executionInfo":{"status":"ok","timestamp":1570800280751,"user_tz":-120,"elapsed":20803,"user":{"displayName":"david cerezal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMo4diOvC7X2o3loNf2tTLcnrDlcvQT2ZBFxsZLA=s64","userId":"10058377044009387405"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["#LMG: Para Google CoLab tener el repo de Drive:\n","if inColab:\n","  from google.colab import drive\n","  drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QPdkUOGTfXeo","colab_type":"text"},"source":["##Carga de librerías y preparación de datos"]},{"cell_type":"markdown","metadata":{"id":"HkrlN5T1kc4V","colab_type":"text"},"source":["Antes de preparar todo, elegimos el modelo a utilizar:"]},{"cell_type":"code","metadata":{"id":"i5CvKf6xkkgJ","colab_type":"code","colab":{}},"source":["useDense = False\n","useLSTM = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ToK0mmmckhAB","colab_type":"text"},"source":["Ahora pasamos a la carga de librerías y preparación de datos:"]},{"cell_type":"code","metadata":{"id":"JZo4Cp7RezA-","colab_type":"code","outputId":"2405e276-c26d-40eb-fa98-0f533ca3918d","executionInfo":{"status":"ok","timestamp":1569677278723,"user_tz":-120,"elapsed":41803,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import keras.backend as K\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, LSTM, Dropout, SimpleRNN, BatchNormalization\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from keras.optimizers import SGD\n","from keras.regularizers import l2\n","from keras.callbacks import EarlyStopping\n","from statsmodels.graphics.tsaplots import plot_acf"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jElUruaqeoFw","colab_type":"code","outputId":"c48ef295-b089-4f29-d002-ec217301e2a0","executionInfo":{"status":"ok","timestamp":1569677279997,"user_tz":-120,"elapsed":43055,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["#LMG: Para CoLab en sample_data:\n","if inColab:\n","  data_consumo = pd.read_csv(\"/content/drive/My Drive/TFM/01.Utils/data/data_total (1).csv\")\n","else:\n","  data_consumo = pd.read_csv(\"data_total.csv\")\n","  \n","data_consumo.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Unnamed: 0.1</th>\n","      <th>fecha</th>\n","      <th>PVPC_DEF</th>\n","      <th>PVPC_2_PED_NOC</th>\n","      <th>PVPC_ELEC_NOC</th>\n","      <th>date_timestamp</th>\n","      <th>Demanda</th>\n","      <th>Eolica</th>\n","      <th>Nuclear</th>\n","      <th>Solar</th>\n","      <th>Solar_Fotovoltaica</th>\n","      <th>Solar_Termica</th>\n","      <th>Termica_Renovable</th>\n","      <th>Prevista</th>\n","      <th>Programada</th>\n","      <th>date_day</th>\n","      <th>Brent_price</th>\n","      <th>Holiday</th>\n","      <th>Precio de Regulación Secundaria subir</th>\n","      <th>Precio de Regulación Secundaria bajar</th>\n","      <th>Precio mercado SPOT Diario_x</th>\n","      <th>Demanda real</th>\n","      <th>Generación prevista Solar</th>\n","      <th>Saldo total interconexiones programa p48</th>\n","      <th>Generación programada P48 Exportación Portugal</th>\n","      <th>Generación programada P48 Exportación Francia</th>\n","      <th>Generación programada P48 Importación Portugal</th>\n","      <th>Generación programada P48 Importación Francia</th>\n","      <th>Precio SPOT PT</th>\n","      <th>Precio SPOT FR</th>\n","      <th>PVPC-target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2015-10-01 00:00:00+02:00</td>\n","      <td>117.77</td>\n","      <td>69.49</td>\n","      <td>71.88</td>\n","      <td>1.443650e+09</td>\n","      <td>24984.666667</td>\n","      <td>1003.666667</td>\n","      <td>6012.833333</td>\n","      <td>402.166667</td>\n","      <td>33.0</td>\n","      <td>368.500000</td>\n","      <td>580.166667</td>\n","      <td>24691.833333</td>\n","      <td>24517.0</td>\n","      <td>2015-10-01</td>\n","      <td>47.48</td>\n","      <td>0.0</td>\n","      <td>61.18</td>\n","      <td>NaN</td>\n","      <td>56.65</td>\n","      <td>25305.0</td>\n","      <td>267.6</td>\n","      <td>182.4</td>\n","      <td>-606.6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1200.0</td>\n","      <td>56.65</td>\n","      <td>38.56</td>\n","      <td>123.30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015-10-01 01:00:00+02:00</td>\n","      <td>117.09</td>\n","      <td>68.21</td>\n","      <td>65.57</td>\n","      <td>1.443654e+09</td>\n","      <td>23550.833333</td>\n","      <td>899.000000</td>\n","      <td>6013.166667</td>\n","      <td>174.833333</td>\n","      <td>33.0</td>\n","      <td>141.333333</td>\n","      <td>584.166667</td>\n","      <td>23440.000000</td>\n","      <td>23169.0</td>\n","      <td>2015-10-01</td>\n","      <td>47.48</td>\n","      <td>0.0</td>\n","      <td>59.59</td>\n","      <td>NaN</td>\n","      <td>53.50</td>\n","      <td>23959.0</td>\n","      <td>195.7</td>\n","      <td>-269.5</td>\n","      <td>-1112.5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1200.0</td>\n","      <td>53.50</td>\n","      <td>31.27</td>\n","      <td>121.98</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2015-10-01 02:00:00+02:00</td>\n","      <td>114.59</td>\n","      <td>65.34</td>\n","      <td>62.53</td>\n","      <td>1.443658e+09</td>\n","      <td>22648.166667</td>\n","      <td>927.500000</td>\n","      <td>6013.500000</td>\n","      <td>103.833333</td>\n","      <td>33.0</td>\n","      <td>70.666667</td>\n","      <td>585.833333</td>\n","      <td>22521.166667</td>\n","      <td>22437.0</td>\n","      <td>2015-10-01</td>\n","      <td>47.48</td>\n","      <td>0.0</td>\n","      <td>56.27</td>\n","      <td>49.13</td>\n","      <td>49.69</td>\n","      <td>22873.0</td>\n","      <td>202.1</td>\n","      <td>94.0</td>\n","      <td>-951.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1200.0</td>\n","      <td>49.69</td>\n","      <td>30.66</td>\n","      <td>126.70</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2015-10-01 03:00:00+02:00</td>\n","      <td>116.60</td>\n","      <td>66.53</td>\n","      <td>63.40</td>\n","      <td>1.443661e+09</td>\n","      <td>22203.833333</td>\n","      <td>935.666667</td>\n","      <td>6013.000000</td>\n","      <td>102.000000</td>\n","      <td>33.0</td>\n","      <td>69.000000</td>\n","      <td>588.500000</td>\n","      <td>22335.333333</td>\n","      <td>22281.0</td>\n","      <td>2015-10-01</td>\n","      <td>47.48</td>\n","      <td>0.0</td>\n","      <td>45.99</td>\n","      <td>45.50</td>\n","      <td>49.10</td>\n","      <td>22550.0</td>\n","      <td>61.3</td>\n","      <td>319.7</td>\n","      <td>-846.3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1200.0</td>\n","      <td>49.10</td>\n","      <td>29.14</td>\n","      <td>131.63</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>2015-10-01 04:00:00+02:00</td>\n","      <td>122.07</td>\n","      <td>71.03</td>\n","      <td>67.37</td>\n","      <td>1.443665e+09</td>\n","      <td>21987.833333</td>\n","      <td>900.833333</td>\n","      <td>6014.166667</td>\n","      <td>101.666667</td>\n","      <td>33.0</td>\n","      <td>68.166667</td>\n","      <td>589.000000</td>\n","      <td>22177.833333</td>\n","      <td>21910.0</td>\n","      <td>2015-10-01</td>\n","      <td>47.48</td>\n","      <td>0.0</td>\n","      <td>52.28</td>\n","      <td>49.13</td>\n","      <td>51.25</td>\n","      <td>22017.0</td>\n","      <td>45.1</td>\n","      <td>405.5</td>\n","      <td>-760.5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1200.0</td>\n","      <td>51.25</td>\n","      <td>29.40</td>\n","      <td>134.73</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  Unnamed: 0.1  ... Precio SPOT FR  PVPC-target\n","0           0             0  ...          38.56       123.30\n","1           1             1  ...          31.27       121.98\n","2           2             2  ...          30.66       126.70\n","3           3             3  ...          29.14       131.63\n","4           4             4  ...          29.40       134.73\n","\n","[5 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"a4DkTkBKTbjI","colab_type":"code","outputId":"e486004c-b730-4b0e-d5fc-17f7a313fff6","executionInfo":{"status":"ok","timestamp":1569677279998,"user_tz":-120,"elapsed":43035,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["data = data_consumo[['PVPC_DEF']]\n","\n","data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PVPC_DEF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>117.77</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>117.09</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>114.59</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>116.60</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>122.07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PVPC_DEF\n","0    117.77\n","1    117.09\n","2    114.59\n","3    116.60\n","4    122.07"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"584WmCVklWvo","colab_type":"text"},"source":["###Formateo de datos para los modelos"]},{"cell_type":"markdown","metadata":{"id":"l-s-AUJ1jtCD","colab_type":"text"},"source":["Generamos el dataset como secuencias de precio:"]},{"cell_type":"code","metadata":{"id":"EVU0VJ48QxXl","colab_type":"code","colab":{}},"source":["# split a sequence into samples\n","def split_sequence(sequence, n_steps):\n","  X = list()\n","  for i in range(len(sequence)):\n","    # find the end of this pattern\n","    end_ix = i + n_steps\n","    # check if we are beyond the sequence\n","    if end_ix > len(sequence)-1:\n","      break\n","    # gather input and output parts of the pattern\n","    seq_x = sequence[i:end_ix,:]\n","    X.append(seq_x)\n","\n","  return np.array(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FtIkBQUL74un","colab_type":"code","outputId":"81efd525-e3e9-45f0-f0d1-ea8b515879bc","executionInfo":{"status":"ok","timestamp":1569677282512,"user_tz":-120,"elapsed":45260,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["split_steps = 100\n","\n","data_processed = split_sequence(data.to_numpy()[:,0:1], split_steps)\n","x_data = data_processed[:,:-1,0]\n","y_data = data_processed[:,-1]\n","# Split the data\n","x_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data, test_size=0.33, shuffle=False)\n","\n","#Convert NaN values to 0:\n","x_train = np.nan_to_num(x_train)\n","x_valid = np.nan_to_num(x_valid)\n","y_train = np.nan_to_num(y_train)\n","y_valid = np.nan_to_num(y_valid)\n","\n","print('Xtrain_dim:', x_train.shape)\n","print('Ytrain_dim:', y_train.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Xtrain_dim: (20404, 99)\n","Ytrain_dim: (20404, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-fbbu7jooUhK","colab_type":"text"},"source":["Veamos cómo queda:"]},{"cell_type":"code","metadata":{"id":"VSm2t-D_oTMh","colab_type":"code","outputId":"54839bd1-fef9-442e-855b-3b65588f9fdc","executionInfo":{"status":"ok","timestamp":1569677282779,"user_tz":-120,"elapsed":45510,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["x_train_DF = pd.DataFrame(x_train)\n","x_train_DF.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.68</td>\n","      <td>2.50</td>\n","      <td>-2.01</td>\n","      <td>-5.47</td>\n","      <td>-3.24</td>\n","      <td>-5.39</td>\n","      <td>-4.99</td>\n","      <td>4.67</td>\n","      <td>0.51</td>\n","      <td>1.77</td>\n","      <td>1.78</td>\n","      <td>2.10</td>\n","      <td>5.61</td>\n","      <td>5.36</td>\n","      <td>-6.72</td>\n","      <td>-10.85</td>\n","      <td>-4.84</td>\n","      <td>4.64</td>\n","      <td>11.70</td>\n","      <td>7.24</td>\n","      <td>-8.35</td>\n","      <td>-1.53</td>\n","      <td>1.56</td>\n","      <td>-2.26</td>\n","      <td>1.32</td>\n","      <td>-4.72</td>\n","      <td>-4.93</td>\n","      <td>-3.10</td>\n","      <td>2.54</td>\n","      <td>-0.02</td>\n","      <td>1.67</td>\n","      <td>2.42</td>\n","      <td>0.59</td>\n","      <td>2.61</td>\n","      <td>5.37</td>\n","      <td>7.42</td>\n","      <td>4.08</td>\n","      <td>-4.67</td>\n","      <td>-8.25</td>\n","      <td>-8.26</td>\n","      <td>...</td>\n","      <td>1.45</td>\n","      <td>-1.55</td>\n","      <td>-10.01</td>\n","      <td>-12.93</td>\n","      <td>-7.22</td>\n","      <td>8.30</td>\n","      <td>9.59</td>\n","      <td>8.67</td>\n","      <td>3.80</td>\n","      <td>0.76</td>\n","      <td>1.39</td>\n","      <td>0.00</td>\n","      <td>1.73</td>\n","      <td>0.49</td>\n","      <td>-2.69</td>\n","      <td>-3.39</td>\n","      <td>-4.40</td>\n","      <td>0.40</td>\n","      <td>4.86</td>\n","      <td>-0.70</td>\n","      <td>1.75</td>\n","      <td>4.22</td>\n","      <td>5.62</td>\n","      <td>3.69</td>\n","      <td>2.71</td>\n","      <td>-1.29</td>\n","      <td>-11.62</td>\n","      <td>-11.47</td>\n","      <td>-13.30</td>\n","      <td>3.53</td>\n","      <td>14.98</td>\n","      <td>7.55</td>\n","      <td>4.03</td>\n","      <td>0.79</td>\n","      <td>-0.43</td>\n","      <td>-2.30</td>\n","      <td>0.08</td>\n","      <td>-1.05</td>\n","      <td>-10.81</td>\n","      <td>-6.86</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.50</td>\n","      <td>-2.01</td>\n","      <td>-5.47</td>\n","      <td>-3.24</td>\n","      <td>-5.39</td>\n","      <td>-4.99</td>\n","      <td>4.67</td>\n","      <td>0.51</td>\n","      <td>1.77</td>\n","      <td>1.78</td>\n","      <td>2.10</td>\n","      <td>5.61</td>\n","      <td>5.36</td>\n","      <td>-6.72</td>\n","      <td>-10.85</td>\n","      <td>-4.84</td>\n","      <td>4.64</td>\n","      <td>11.70</td>\n","      <td>7.24</td>\n","      <td>-8.35</td>\n","      <td>-1.53</td>\n","      <td>1.56</td>\n","      <td>-2.26</td>\n","      <td>1.32</td>\n","      <td>-4.72</td>\n","      <td>-4.93</td>\n","      <td>-3.10</td>\n","      <td>2.54</td>\n","      <td>-0.02</td>\n","      <td>1.67</td>\n","      <td>2.42</td>\n","      <td>0.59</td>\n","      <td>2.61</td>\n","      <td>5.37</td>\n","      <td>7.42</td>\n","      <td>4.08</td>\n","      <td>-4.67</td>\n","      <td>-8.25</td>\n","      <td>-8.26</td>\n","      <td>-7.55</td>\n","      <td>...</td>\n","      <td>-1.55</td>\n","      <td>-10.01</td>\n","      <td>-12.93</td>\n","      <td>-7.22</td>\n","      <td>8.30</td>\n","      <td>9.59</td>\n","      <td>8.67</td>\n","      <td>3.80</td>\n","      <td>0.76</td>\n","      <td>1.39</td>\n","      <td>0.00</td>\n","      <td>1.73</td>\n","      <td>0.49</td>\n","      <td>-2.69</td>\n","      <td>-3.39</td>\n","      <td>-4.40</td>\n","      <td>0.40</td>\n","      <td>4.86</td>\n","      <td>-0.70</td>\n","      <td>1.75</td>\n","      <td>4.22</td>\n","      <td>5.62</td>\n","      <td>3.69</td>\n","      <td>2.71</td>\n","      <td>-1.29</td>\n","      <td>-11.62</td>\n","      <td>-11.47</td>\n","      <td>-13.30</td>\n","      <td>3.53</td>\n","      <td>14.98</td>\n","      <td>7.55</td>\n","      <td>4.03</td>\n","      <td>0.79</td>\n","      <td>-0.43</td>\n","      <td>-2.30</td>\n","      <td>0.08</td>\n","      <td>-1.05</td>\n","      <td>-10.81</td>\n","      <td>-6.86</td>\n","      <td>1.69</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.01</td>\n","      <td>-5.47</td>\n","      <td>-3.24</td>\n","      <td>-5.39</td>\n","      <td>-4.99</td>\n","      <td>4.67</td>\n","      <td>0.51</td>\n","      <td>1.77</td>\n","      <td>1.78</td>\n","      <td>2.10</td>\n","      <td>5.61</td>\n","      <td>5.36</td>\n","      <td>-6.72</td>\n","      <td>-10.85</td>\n","      <td>-4.84</td>\n","      <td>4.64</td>\n","      <td>11.70</td>\n","      <td>7.24</td>\n","      <td>-8.35</td>\n","      <td>-1.53</td>\n","      <td>1.56</td>\n","      <td>-2.26</td>\n","      <td>1.32</td>\n","      <td>-4.72</td>\n","      <td>-4.93</td>\n","      <td>-3.10</td>\n","      <td>2.54</td>\n","      <td>-0.02</td>\n","      <td>1.67</td>\n","      <td>2.42</td>\n","      <td>0.59</td>\n","      <td>2.61</td>\n","      <td>5.37</td>\n","      <td>7.42</td>\n","      <td>4.08</td>\n","      <td>-4.67</td>\n","      <td>-8.25</td>\n","      <td>-8.26</td>\n","      <td>-7.55</td>\n","      <td>14.92</td>\n","      <td>...</td>\n","      <td>-10.01</td>\n","      <td>-12.93</td>\n","      <td>-7.22</td>\n","      <td>8.30</td>\n","      <td>9.59</td>\n","      <td>8.67</td>\n","      <td>3.80</td>\n","      <td>0.76</td>\n","      <td>1.39</td>\n","      <td>0.00</td>\n","      <td>1.73</td>\n","      <td>0.49</td>\n","      <td>-2.69</td>\n","      <td>-3.39</td>\n","      <td>-4.40</td>\n","      <td>0.40</td>\n","      <td>4.86</td>\n","      <td>-0.70</td>\n","      <td>1.75</td>\n","      <td>4.22</td>\n","      <td>5.62</td>\n","      <td>3.69</td>\n","      <td>2.71</td>\n","      <td>-1.29</td>\n","      <td>-11.62</td>\n","      <td>-11.47</td>\n","      <td>-13.30</td>\n","      <td>3.53</td>\n","      <td>14.98</td>\n","      <td>7.55</td>\n","      <td>4.03</td>\n","      <td>0.79</td>\n","      <td>-0.43</td>\n","      <td>-2.30</td>\n","      <td>0.08</td>\n","      <td>-1.05</td>\n","      <td>-10.81</td>\n","      <td>-6.86</td>\n","      <td>1.69</td>\n","      <td>-4.61</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-5.47</td>\n","      <td>-3.24</td>\n","      <td>-5.39</td>\n","      <td>-4.99</td>\n","      <td>4.67</td>\n","      <td>0.51</td>\n","      <td>1.77</td>\n","      <td>1.78</td>\n","      <td>2.10</td>\n","      <td>5.61</td>\n","      <td>5.36</td>\n","      <td>-6.72</td>\n","      <td>-10.85</td>\n","      <td>-4.84</td>\n","      <td>4.64</td>\n","      <td>11.70</td>\n","      <td>7.24</td>\n","      <td>-8.35</td>\n","      <td>-1.53</td>\n","      <td>1.56</td>\n","      <td>-2.26</td>\n","      <td>1.32</td>\n","      <td>-4.72</td>\n","      <td>-4.93</td>\n","      <td>-3.10</td>\n","      <td>2.54</td>\n","      <td>-0.02</td>\n","      <td>1.67</td>\n","      <td>2.42</td>\n","      <td>0.59</td>\n","      <td>2.61</td>\n","      <td>5.37</td>\n","      <td>7.42</td>\n","      <td>4.08</td>\n","      <td>-4.67</td>\n","      <td>-8.25</td>\n","      <td>-8.26</td>\n","      <td>-7.55</td>\n","      <td>14.92</td>\n","      <td>9.09</td>\n","      <td>...</td>\n","      <td>-12.93</td>\n","      <td>-7.22</td>\n","      <td>8.30</td>\n","      <td>9.59</td>\n","      <td>8.67</td>\n","      <td>3.80</td>\n","      <td>0.76</td>\n","      <td>1.39</td>\n","      <td>0.00</td>\n","      <td>1.73</td>\n","      <td>0.49</td>\n","      <td>-2.69</td>\n","      <td>-3.39</td>\n","      <td>-4.40</td>\n","      <td>0.40</td>\n","      <td>4.86</td>\n","      <td>-0.70</td>\n","      <td>1.75</td>\n","      <td>4.22</td>\n","      <td>5.62</td>\n","      <td>3.69</td>\n","      <td>2.71</td>\n","      <td>-1.29</td>\n","      <td>-11.62</td>\n","      <td>-11.47</td>\n","      <td>-13.30</td>\n","      <td>3.53</td>\n","      <td>14.98</td>\n","      <td>7.55</td>\n","      <td>4.03</td>\n","      <td>0.79</td>\n","      <td>-0.43</td>\n","      <td>-2.30</td>\n","      <td>0.08</td>\n","      <td>-1.05</td>\n","      <td>-10.81</td>\n","      <td>-6.86</td>\n","      <td>1.69</td>\n","      <td>-4.61</td>\n","      <td>0.78</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-3.24</td>\n","      <td>-5.39</td>\n","      <td>-4.99</td>\n","      <td>4.67</td>\n","      <td>0.51</td>\n","      <td>1.77</td>\n","      <td>1.78</td>\n","      <td>2.10</td>\n","      <td>5.61</td>\n","      <td>5.36</td>\n","      <td>-6.72</td>\n","      <td>-10.85</td>\n","      <td>-4.84</td>\n","      <td>4.64</td>\n","      <td>11.70</td>\n","      <td>7.24</td>\n","      <td>-8.35</td>\n","      <td>-1.53</td>\n","      <td>1.56</td>\n","      <td>-2.26</td>\n","      <td>1.32</td>\n","      <td>-4.72</td>\n","      <td>-4.93</td>\n","      <td>-3.10</td>\n","      <td>2.54</td>\n","      <td>-0.02</td>\n","      <td>1.67</td>\n","      <td>2.42</td>\n","      <td>0.59</td>\n","      <td>2.61</td>\n","      <td>5.37</td>\n","      <td>7.42</td>\n","      <td>4.08</td>\n","      <td>-4.67</td>\n","      <td>-8.25</td>\n","      <td>-8.26</td>\n","      <td>-7.55</td>\n","      <td>14.92</td>\n","      <td>9.09</td>\n","      <td>4.25</td>\n","      <td>...</td>\n","      <td>-7.22</td>\n","      <td>8.30</td>\n","      <td>9.59</td>\n","      <td>8.67</td>\n","      <td>3.80</td>\n","      <td>0.76</td>\n","      <td>1.39</td>\n","      <td>0.00</td>\n","      <td>1.73</td>\n","      <td>0.49</td>\n","      <td>-2.69</td>\n","      <td>-3.39</td>\n","      <td>-4.40</td>\n","      <td>0.40</td>\n","      <td>4.86</td>\n","      <td>-0.70</td>\n","      <td>1.75</td>\n","      <td>4.22</td>\n","      <td>5.62</td>\n","      <td>3.69</td>\n","      <td>2.71</td>\n","      <td>-1.29</td>\n","      <td>-11.62</td>\n","      <td>-11.47</td>\n","      <td>-13.30</td>\n","      <td>3.53</td>\n","      <td>14.98</td>\n","      <td>7.55</td>\n","      <td>4.03</td>\n","      <td>0.79</td>\n","      <td>-0.43</td>\n","      <td>-2.30</td>\n","      <td>0.08</td>\n","      <td>-1.05</td>\n","      <td>-10.81</td>\n","      <td>-6.86</td>\n","      <td>1.69</td>\n","      <td>-4.61</td>\n","      <td>0.78</td>\n","      <td>2.12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 99 columns</p>\n","</div>"],"text/plain":["     0     1     2     3     4     5   ...     93     94     95     96     97    98\n","0  0.68  2.50 -2.01 -5.47 -3.24 -5.39  ...  -0.43  -2.30   0.08  -1.05 -10.81 -6.86\n","1  2.50 -2.01 -5.47 -3.24 -5.39 -4.99  ...  -2.30   0.08  -1.05 -10.81  -6.86  1.69\n","2 -2.01 -5.47 -3.24 -5.39 -4.99  4.67  ...   0.08  -1.05 -10.81  -6.86   1.69 -4.61\n","3 -5.47 -3.24 -5.39 -4.99  4.67  0.51  ...  -1.05 -10.81  -6.86   1.69  -4.61  0.78\n","4 -3.24 -5.39 -4.99  4.67  0.51  1.77  ... -10.81  -6.86   1.69  -4.61   0.78  2.12\n","\n","[5 rows x 99 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"gOBegpcjmZZd","colab_type":"code","outputId":"0905f70c-5543-46ad-d89e-fa08901fc490","executionInfo":{"status":"ok","timestamp":1569677282780,"user_tz":-120,"elapsed":45491,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["y_train_DF = pd.DataFrame(y_train)\n","y_train_DF.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.69</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-4.61</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.78</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.12</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0\n","0  1.69\n","1 -4.61\n","2  0.78\n","3  2.12\n","4  3.17"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"z5psOKAClj4y","colab_type":"text"},"source":["Por último, generamos funciones y variables de utilidad a lo largo de todos los modelos:"]},{"cell_type":"code","metadata":{"id":"ngqVXGPnlxYe","colab_type":"code","colab":{}},"source":["def rmse (y_true, y_pred):\n","  return K.sqrt(K.mean(K.square(y_pred -y_true), axis=-1))\n","\n","\n","## ????\n","def mad (y_true, y_pred): \n","  return K.sqrt(K.mean(K.square(y_pred -y_true), axis=-1))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tVL1EhJ5j9OF","colab_type":"text"},"source":["##Ejemplo de NN"]},{"cell_type":"markdown","metadata":{"id":"clY1_9ZXkCjv","colab_type":"text"},"source":["Red neuronal densa como punto de partida."]},{"cell_type":"markdown","metadata":{"id":"QGWYIwS0kIQ9","colab_type":"text"},"source":["###Preparación y entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"dHjNvrllleGT","colab_type":"text"},"source":["Primero, estandarizamos los **datos de entrenamiento**:"]},{"cell_type":"code","metadata":{"id":"0vfeGor-lfAQ","colab_type":"code","colab":{}},"source":["if useDense:\n","  scaler = MinMaxScaler()\n","  x_train_data = scaler.fit_transform(x_train)\n","  y_train_data = scaler.fit_transform(y_train)\n","  x_valid_data = x_valid\n","  y_valid_data = y_valid\n","\n","  print('Entrenamiento:',x_train_data.shape, y_train_data.shape)\n","  print('Test:',x_valid_data.shape, y_valid_data.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x4Letj1gnWRY"},"source":["Por último, definimos los tamaños de nuestra red y algunas variables adicionales"]},{"cell_type":"code","metadata":{"id":"spfo1BpxlM8J","colab_type":"code","colab":{}},"source":["if useDense:\n","  batch_size = 5\n","  num_var = x_train_data.shape[1]\n","  hidden_size = 20\n","  output_size = y_train_data.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IfvcqGxFm4V5","colab_type":"text"},"source":["###Modelo"]},{"cell_type":"code","metadata":{"id":"SZVFlBUKm7fq","colab_type":"code","colab":{}},"source":["if useDense:\n","  # define model\n","  model = Sequential()\n","  model.add(Dense(hidden_size, \n","                  activation='relu',\n","                  input_shape=(num_var,),\n","                  kernel_regularizer=l2(1e-2)))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(hidden_size, \n","                  activation='relu',\n","                  kernel_regularizer=l2(1e-2)))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(output_size,\n","                  activation='linear',\n","                  kernel_regularizer=l2(1e-2)))\n","\n","  # compile mode\n","  opt='adam'\n","  model.compile(optimizer=opt, loss='mse', metrics=['mse',rmse,'mae','mape'])\n","  print(model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"24K8XGk7Eirr","colab_type":"text"},"source":["##Ejemplo de LSTM"]},{"cell_type":"markdown","metadata":{"id":"9AOyGsv9Qx20","colab_type":"text"},"source":["Basado en el ejemplo completo que está explicado en https://adventuresinmachinelearning.com/keras-lstm-tutorial/"]},{"cell_type":"markdown","metadata":{"id":"Z-jm158mKJHA","colab_type":"text"},"source":["###Preparación y entrenamiento"]},{"cell_type":"code","metadata":{"id":"A6c_j69eRfQv","colab_type":"code","outputId":"2212b3ef-0245-4fd3-ba2a-0c8c286c25af","executionInfo":{"status":"ok","timestamp":1569677282788,"user_tz":-120,"elapsed":45455,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["if useLSTM:\n","  x_train_data = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","  y_train_data = y_train\n","  \n","  x_valid_data = x_valid.reshape((x_valid.shape[0], x_valid.shape[1], 1))\n","  y_valid_data = y_valid\n","\n","  print('Entrenamiento:',x_train_data.shape, y_train_data.shape)\n","  print('Test:',x_valid_data.shape, y_valid_data.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Entrenamiento: (20404, 99, 1) (20404, 1)\n","Test: (10051, 99, 1) (10051, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H95jxroYS-i7","colab_type":"text"},"source":["Definimos los tamaños de nuestra red y algunas variables adicionales:\n","\n","En nuestro caso, la entrada va a ser de *1* **x** *nº de datos tomados* **x** *nº de variables independientes*, siendo:\n","\n","- batch_size, para cada instante tomamos los datos en paquetes.\n","- nº de datos tomados o num_steps, esto es, en el análisis secuencial cada registro energético completo con el que contamos, o en términos más coloquiales, cuántas filas del dataset se tienen en cuenta .\n","- nº de variables independientes o num_var, cada registro en los datos de entrada, o en términos más coloquiales, cada columna del dataset.\n","\n","Además:\n","\n","- hidden_size, número de unidades en cada célula del LSTM.\n","\n","- A la salida, tenemos los tres valores a estimar."]},{"cell_type":"code","metadata":{"id":"BdkHAnbBS-_U","colab_type":"code","colab":{}},"source":["if useLSTM:\n","  num_steps = split_steps - 1\n","  num_var = x_train_data.shape[2]\n","  output_size = y_train_data.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iwb93rKXmr0K","colab_type":"text"},"source":["###Modelo"]},{"cell_type":"markdown","metadata":{"id":"2xArQLrgE8g-","colab_type":"text"},"source":["A la capa LSTM se le pasa cada vez un instante, siendo el primero el t1, el segundo el t2, etc.\n","\n","Respecto al ejemplo en la página, hemos:\n","- Quitado el embedding inicial, ya que no necesitamos codificar la entrada (ya son valores en sí mismos).\n","- Cambiado el hidden-layer-size. En la página dicen que se suele poner al tamaño de entrada de cada registro. Viene a ser el símil de unidades en una capa densa.\n","- Dejado una única capa LSTM.\n","- Eliminado el dropout.\n","- TimeDistributed usa una capa densa para cada step del entrenamiento. La quitamos también y dejamos la densa exclusivamente, ya que hace la salida muy grande.\n","\n","Así:\n"]},{"cell_type":"code","metadata":{"id":"L1xmNZVPHVVd","colab_type":"code","outputId":"348d8578-641e-4ccd-82eb-c2bb6833dbd9","executionInfo":{"status":"ok","timestamp":1569677494635,"user_tz":-120,"elapsed":1374,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/","height":666}},"source":["if useLSTM:\n","  # define model\n","  model = Sequential()\n","  model.add(SimpleRNN(50,\n","                    activation='relu',\n","                    kernel_regularizer=l2(0.001),\n","                    return_sequences=True,\n","                    input_shape=(num_steps,num_var)))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.2))\n","\n","  model.add(SimpleRNN(50,\n","                      activation='relu',\n","                      kernel_regularizer=l2(0.001),\n","                      return_sequences=True))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.2))\n","\n","  model.add(SimpleRNN(50,\n","                      activation='relu',\n","                      kernel_regularizer=l2(0.001)))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.2))\n","  \n","  model.add(Dense(output_size,\n","                 activation='linear',\n","                 kernel_regularizer=l2(0.001)))\n","\n","  # compile mode\n","  model.compile(optimizer='adam', loss='mse', metrics=['mse',rmse,'mae','mape'])\n","  model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","simple_rnn_10 (SimpleRNN)    (None, 99, 50)            2600      \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 99, 50)            200       \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 99, 50)            0         \n","_________________________________________________________________\n","simple_rnn_11 (SimpleRNN)    (None, 99, 50)            5050      \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 99, 50)            200       \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 99, 50)            0         \n","_________________________________________________________________\n","simple_rnn_12 (SimpleRNN)    (None, 50)                5050      \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 50)                200       \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 50)                0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 51        \n","=================================================================\n","Total params: 13,351\n","Trainable params: 13,051\n","Non-trainable params: 300\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OCUaeBOpRgbN","colab_type":"text"},"source":["##Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"TOlMJFcJIeGO","colab_type":"text"},"source":["Entrenamos el modelo seleccionado:"]},{"cell_type":"code","metadata":{"id":"fFKaJjCCHlT1","colab_type":"code","outputId":"be638916-1727-4ed7-f7a8-9c11019582a6","executionInfo":{"status":"error","timestamp":1569666359541,"user_tz":-120,"elapsed":108432,"user":{"displayName":"Luis Miguel Gil","photoUrl":"","userId":"02399746530348164073"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["# simple early stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)\n","\n","if useDense:\n","  print('DENSE')\n","  history_train = model.fit(x_train_data, y_train_data, \n","                            epochs=5, \n","                            batch_size=batch_size, \n","                            shuffle=False,\n","                            verbose=1)\n","\n","if useLSTM:\n","  print('LSTM')\n","  history_train = model.fit(x_train_data, y_train_data, \n","                            epochs=50, \n","                            batch_size=30, \n","                            shuffle=False,\n","                            validation_split=0.3,\n","                            callbacks=[es],\n","                            verbose=1)\n","\n","# summarize history for loss, MAPE in a different scale than the others\n","plt.plot(history_train.history['mean_squared_error'])\n","plt.plot(history_train.history['mean_absolute_error'])\n","plt.plot(history_train.history['rmse'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['MSE','MAE','RMSE'], loc='upper left')\n","plt.show()\n","\n","plt.plot(history_train.history['mean_absolute_percentage_error'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['MAPE'], loc='upper left')\n","plt.show()\n","\n","#Comments sobre las metrics: \n","\n","#Sobre MSE supongamos que tenemos la real de 0.6 y la pred de 0.3 como en los ejemplos, \n","#Esto nos deja un error de 0.3, en el MSE 0.3^2 = 0.09, \n","#es decir no concuerda con el MSE que nos sale de media 0.009\n","#Este MSE de 0.0092 significa que tenemos un error medio de 0.094 = Raiz(0.0092)\n","#Igualmente este error no es mucho, pero tampoco es bueno, significa que en el max min, \n","#Entre 0 y 1 tenemos que el error medio es de 0.1, en real pueden ser como 20€, \n","#que siendo un valor de 0 a 1 es bastante, no ajusta bien el precio!!\n","\n","#El MAE lo confirma, este se acerca al 0.1, siendo del 0.07\n","#Este es el error medio, sin raíces si squared.\n","\n","#Habría que ver como sale este valor para los valores reales, y que MSE Y RMSE da. \n","#Si el MSE es de 0.0\n","\n","#En consecuencia el MAPE, se nos va por las nubes, porque es el porcentaje del error frente al \n","#valor verdaero, como hay un error muy grande, el porcentaje es grande y se nos va\n","\n","#Tenemos que ver: \n","#1.- Predicción con los valores sin scalar\n","#2.- Plot del prediccion total con el inversed value, para ver de verdad que predice.\n","#3.- MAD metric podría ser intersante"],"execution_count":0,"outputs":[{"output_type":"stream","text":["LSTM\n","Train on 14282 samples, validate on 6122 samples\n","Epoch 1/50\n","  360/14282 [..............................] - ETA: 26s - loss: 28.8782 - mean_squared_error: 28.7716 - rmse: 4.0012 - mean_absolute_error: 4.0012 - mean_absolute_percentage_error: 2298256.2782"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R3p_zOt6KPey","colab_type":"text"},"source":["##Test"]},{"cell_type":"markdown","metadata":{"id":"xg6-Qtdai-3y","colab_type":"text"},"source":["Para el test:"]},{"cell_type":"code","metadata":{"id":"ZAlosve8i-nO","colab_type":"code","colab":{}},"source":["if useDense:\n","  scores_test = model.evaluate(x_valid_data, y_valid_data, batch_size=batch_size, verbose=1)\n","\n","if useLSTM:\n","  scores_test = model.evaluate(x_valid_data, y_valid_data, batch_size=batch_size, verbose=1)\n","\n","  # summarize loss\n","  for element in range(len(scores_test)):\n","    print(\"%s: %.2f\" % (model.metrics_names[element], scores_test[element]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_taCWoCkH7wE","colab_type":"code","colab":{}},"source":["if useDense:\n","  x_valid_data_DF = pd.DataFrame(x_valid_data)\n","  \n","if useLSTM:\n","  x_valid_data_DF = pd.DataFrame(x_valid_data[:,:,0])\n","  \n","x_valid_data_DF.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXPhcdY8IwpI","colab_type":"code","colab":{}},"source":["if useDense:\n","  y_valid_data_DF = pd.DataFrame(y_valid_data)\n","  \n","if useLSTM:\n","  y_valid_data_DF = pd.DataFrame(y_valid_data)\n","  \n","y_valid_data_DF.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyj3VoxayU2B","colab_type":"text"},"source":["Valores que tratamos que sean iguales:"]},{"cell_type":"code","metadata":{"id":"4jigckeRuZTr","colab_type":"code","colab":{}},"source":["print(y_valid_data[0:9])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"15kRqvNYIdPR","colab_type":"code","colab":{}},"source":["if useDense:\n","  print('DENSE')\n","  prediction = model.predict(x_valid_data[0:9,:], verbose=1)\n","\n","if useLSTM:\n","  print('LSTM')\n","  prediction = model.predict(x_valid_data[0:9,:,:], verbose=1)\n","\n","print(prediction)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OnSzWHjiVuO","colab_type":"code","colab":{}},"source":["x_train_data_temp = x_train_data\n","y_train_data_temp = y_train_data\n","\n","for i_pred in range(1,25):\n","  prediction = model.predict(x_valid_data[(i_pred-1):i_pred,:], verbose=1)\n","  x_train_data_temp = np.append(x_train_data_temp, x_valid_data[(i_pred-1):i_pred, :], axis=0)\n","  y_train_data_temp = np.append(y_train_data_temp, prediction, axis=0)\n","  \n"," \n","  y_pred_val = scaler.inverse_transform(prediction)\n","  y_true_val = scaler.inverse_transform(y_valid_data[(i_pred-1):i_pred,:])\n","  print('True_val not sacled:',y_valid_data[(i_pred-1):i_pred,:])\n","  print('Pred_val not sacled:',prediction)\n","  print('True_val:',y_true_val)\n","  print('Pred_val:',y_pred_val)\n","  print('Perdida en €:',(y_true_val-y_pred_val))\n","  model.train_on_batch(x_train_data_temp, y_train_data_temp)\n","  \n","#Al Pasar un día debería hacer un fit de nuevo total, con los valores de verdad, pero estos predichos siguen siendo shit!  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwjvPs9jdcBR","colab_type":"code","colab":{}},"source":[" prediction = model.predict_on_batch(x_valid_data[0:9,:,:])\n"," print(prediction)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWUYZwJY6j7n","colab_type":"code","colab":{}},"source":["#Pesos\n","for layer in model.layers:\n","    print(layer.get_weights()[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Oy7nhmILU8g","colab_type":"code","colab":{}},"source":["#Biases\n","for layer in model.layers:\n","    print(layer.get_weights()[1])"],"execution_count":0,"outputs":[]}]}